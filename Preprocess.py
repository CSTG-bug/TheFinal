#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½ å¯ä»¥ã€æ‰‹åŠ¨æŒ‡å®šã€‘è¾“å…¥ç‰¹å¾åˆ—å’Œç›®æ ‡åˆ—ï¼›ä¸åšè‡ªåŠ¨åˆ—è¯†åˆ«ã€‚é»˜è®¤ä¹Ÿä¸åšç¼ºå¤±å€¼å¡«è¡¥ï¼Œè‹¥å­˜åœ¨ç¼ºå¤±ä¼šç»™å‡ºæŠ¥é”™ï¼Œ
æ–¹ä¾¿ä½ åœ¨å»ºåº“é˜¶æ®µè‡ªå·±æ¸…æ´—ã€‚

åŠŸèƒ½è¦ç‚¹
--------
1) ä»…ä½¿ç”¨ä½ é€šè¿‡ --features æŒ‡å®šçš„åˆ—ä½œä¸ºè¾“å…¥ç‰¹å¾ï¼›--target æŒ‡å®šç›®æ ‡åˆ—ã€‚
2) è®­ç»ƒ/æµ‹è¯•åˆ’åˆ†ï¼ˆå¯åˆ†å±‚ï¼ŒæŒ‰ç›®æ ‡å€¼åˆ†ç®±ï¼›æç«¯æƒ…å†µä¸‹è‡ªåŠ¨å›é€€æˆæ™®é€šåˆ’åˆ†ï¼‰ã€‚
3) å¯é€‰æ ‡å‡†åŒ–ï¼ˆ--scaleï¼‰ï¼Œé»˜è®¤å¼€å¯ï¼›å…³é—­å°±å»æ‰ä»»ä½•ç¼©æ”¾ã€‚
4) å¯é€‰ç¼ºå¤±å€¼å¡«è¡¥ï¼ˆ--imputeï¼‰ï¼Œé»˜è®¤ noneï¼ˆä¸å¡«è¡¥ï¼Œé‡ç¼ºå¤±ç›´æ¥æŠ¥é”™ï¼‰ã€‚
5) äº§ç‰©ï¼š
   - é¢„å¤„ç†åçš„è®­ç»ƒ/æµ‹è¯•é›†ï¼ˆCSVï¼‰ï¼Œæ–‡ä»¶å/è·¯å¾„ä½ å¯å®Œå…¨è‡ªå®šä¹‰ï¼›
   - å¯é€‰ä¿å­˜ä¸€ä¸ª .npzï¼ˆNumpy æ ¼å¼ï¼‰ä¾¿äºåç»­ç›´æ¥åŠ è½½ï¼ˆ--save-npzï¼‰ã€‚
6) é›†æˆ MAPE å‡½æ•°ï¼ˆä¾›åç»­è¯„ä¼°è„šæœ¬å¤ç”¨ï¼‰ï¼Œæœ¬è„šæœ¬ä¸è®¡ç®— MAPE/R2ï¼ˆå»ºæ¨¡é˜¶æ®µå†ç®—ï¼‰ã€‚

æ³¨æ„
----
- Excel é»˜è®¤è¯»å–ç¬¬ 1 ä¸ª sheetï¼›å¦‚éœ€æŒ‡å®š sheetï¼Œä¼  --sheet 0 æˆ– --sheet "Sheet1"ã€‚
- è‹¥ä½ çš„ç‰¹å¾åé‡Œæœ‰ç©ºæ ¼ï¼Œè¯·ç¡®ä¿æ­£ç¡®è¾“å…¥ï¼ˆå¦‚ "SS Temp"ï¼‰ã€‚
- å¦‚æœä½ è‡ªå·±å®Œå…¨ä¿è¯æ— ç¼ºå¤±ä¸æ— éæ•°å€¼ï¼Œåˆ™å»ºè®®ä½¿ç”¨ --impute noneï¼ˆé»˜è®¤ï¼‰ã€‚
"""
import argparse
from pathlib import Path
from typing import List, Tuple

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

SEED = 42

# -------------------------
# æŒ‡æ ‡å‡½æ•°ï¼ˆåç»­å»ºæ¨¡è„šæœ¬å¯å¯¼å…¥æˆ–å¤åˆ¶ï¼‰
# -------------------------
def mean_absolute_percentage_error(y_true, y_pred) -> float:
    """
    å¯¹ y_true çš„ 0 åšæå°å€¼ä¿æŠ¤ï¼Œé¿å…é™¤é›¶ã€‚
    è¿”å›ç™¾åˆ†æ•°ï¼ˆ0-100ï¼‰ã€‚
    """
    y_true = np.array(y_true, dtype=float)
    y_pred = np.array(y_pred, dtype=float)
    y_true = np.where(y_true == 0, 1e-10, y_true)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100.0

# -------------------------
# å·¥å…·å‡½æ•°
# -------------------------
def parse_feature_list(s: str) -> List[str]:
    """
    å°†é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²è§£æä¸ºåˆ—ååˆ—è¡¨ã€‚å…è®¸åˆ—ååŒ…å«ç©ºæ ¼ï¼ˆä¸ä¼šå»æ‰ä¸­é—´ç©ºæ ¼ï¼‰ã€‚
    ä¼šå¯¹æ¯ä¸ªç‰‡æ®µåš strip() å»é™¤é¦–å°¾ç©ºç™½ã€‚
    """
    return [x.strip() for x in s.split(",") if x.strip()]

def coerce_numeric(df: pd.DataFrame) -> pd.DataFrame:
    """
    å°† DataFrame ä¸­çš„åˆ—å°½é‡è½¬ä¸ºæ•°å€¼ï¼ˆerrors='coerce'ï¼‰ï¼Œéæ•°å€¼ä¼šå˜ä¸º NaNã€‚
    ä¹‹æ‰€ä»¥è¿™æ ·åšï¼šæœ‰æ—¶è¯»å…¥åæ˜¯å­—ç¬¦ä¸²å½¢å¼çš„æ•°å­—ï¼ˆå¦‚ '0.25'ï¼‰ï¼Œå…ˆè½¬æˆæ•°å€¼ï¼Œåç»­æ‰å¥½æ£€æŸ¥ç¼ºå¤±æˆ–åšç¼©æ”¾ã€‚
    """
    out = df.copy()
    for c in out.columns:
        out[c] = pd.to_numeric(out[c], errors="coerce")
    return out

# -------------------------
# ä¸»æµç¨‹
# -------------------------
def preprocess(
    input_path: str,
    target_col: str,
    feature_cols: List[str],
    test_size: float = 0.3,
    random_state: int = SEED,
    sheet: int | str | None = None,
    do_scale: bool = True,
    impute: str = "none",   # "none" | "median" | "mean" | "zero"
    outdir: str | None = None,
    prefix: str = "",
    save_csv: bool = True,
    save_npz: bool = False,
    xtrain_file: str | None = None,
    xtest_file: str | None = None,
    ytrain_file: str | None = None,
    ytest_file: str | None = None,
    save_raw: bool = True,
    xtrain_raw_file: str | None = None,
    xtest_raw_file: str | None = None,
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """
    è¿”å›ï¼šX_train, X_test, y_train, y_test
    åŒæ—¶æ ¹æ®å‚æ•°å†™å‡ºåˆ°ä½ æŒ‡å®šçš„ä½ç½®/æ–‡ä»¶åã€‚
    """
    p = Path(input_path)
    if not p.exists():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")

    # è¯»å–æ–‡ä»¶
    if p.suffix.lower() == ".csv":
        df = pd.read_csv(p)
    elif p.suffix.lower() in [".xls", ".xlsx"]:
        df = pd.read_excel(p, sheet_name=0 if sheet is None else sheet)
    else:
        raise ValueError("ä»…æ”¯æŒ .csv / .xls(x)")

    # ä»…ä¿ç•™ç”¨æˆ·æ˜ç¡®æŒ‡å®šçš„åˆ—ï¼ˆä¸åšä»»ä½•è‡ªåŠ¨å‰”é™¤/è¡¥é½ï¼‰
    missing = [c for c in [target_col] + feature_cols if c not in df.columns]
    if missing:
        raise KeyError(f"ä»¥ä¸‹åˆ—åœ¨æ•°æ®ä¸­æœªæ‰¾åˆ°ï¼š{missing}\nå¯ç”¨åˆ—ä¸ºï¼š{list(df.columns)}")

    y = df[target_col].copy()
    X = df[feature_cols].copy()

    # ç›®æ ‡å¤„ç†ï¼šæå°å€¼ä¿æŠ¤ï¼ˆä¸º MAPE åšå‡†å¤‡ï¼‰ï¼Œå…¶ä½™ä¸åšé¢å¤–æ¸…æ´—
    y = pd.to_numeric(y, errors="coerce").replace([np.inf, -np.inf], np.nan).dropna()
    valid_idx = y.index
    y = y.clip(lower=1e-6)

    # å¯¹é½ç‰¹å¾
    X = X.loc[valid_idx]

    # å°†ç‰¹å¾å°½é‡è½¬ä¸ºæ•°å€¼
    X = coerce_numeric(X)

    # ç¼ºå¤±å¤„ç†
    if impute == "none":
        # è‹¥æœ‰ç¼ºå¤±ï¼Œç›´æ¥æŠ¥é”™ï¼Œæé†’ä½ å…ˆåœ¨å»ºåº“é˜¶æ®µæ¸…ç†
        if X.isna().any().any():
            na_cols = X.columns[X.isna().any()].tolist()
            raise ValueError(f"æ£€æµ‹åˆ°ç¼ºå¤±å€¼ï¼ˆimpute=noneï¼‰ï¼Œè¯·å…ˆåœ¨æ•°æ®å±‚é¢æ¸…ç†ã€‚å«ç¼ºå¤±çš„åˆ—ï¼š{na_cols}")
    elif impute == "median":
        X = X.fillna(X.median())
    elif impute == "mean":
        X = X.fillna(X.mean())
    elif impute == "zero":
        X = X.fillna(0.0)
    else:
        raise ValueError("impute å‚æ•°å¿…é¡»æ˜¯ none/median/mean/zero ä¹‹ä¸€")

    # è®­ç»ƒ/æµ‹è¯•åˆ’åˆ†ï¼ˆä¼˜å…ˆåˆ†å±‚ï¼Œå¤±è´¥åˆ™å›é€€ï¼‰
    stratify = None
    try:
        bins = pd.qcut(y, q=min(10, max(3, int(np.sqrt(len(y))))), duplicates="drop")
        stratify = bins
    except Exception:
        stratify = None
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=stratify
    )

    X_train_raw = X_train.copy()
    X_test_raw  = X_test.copy()

    # ç‰¹å¾ç¼©æ”¾
    if do_scale:
        scaler = StandardScaler()
        X_train_arr = scaler.fit_transform(X_train)
        X_test_arr = scaler.transform(X_test)
        X_train = pd.DataFrame(X_train_arr, index=X_train.index, columns=feature_cols)
        X_test = pd.DataFrame(X_test_arr, index=X_test.index, columns=feature_cols)

    # è¾“å‡ºè·¯å¾„å’Œæ–‡ä»¶å
    if outdir is None:
        out_dir = p.parent
    else:
        out_dir = Path(outdir)
        out_dir.mkdir(parents=True, exist_ok=True)

    # é»˜è®¤æ–‡ä»¶åï¼ˆå¯è¢«æ˜¾å¼å‚æ•°è¦†ç›–ï¼‰
    xtrain_path = out_dir / (xtrain_file if xtrain_file else f"{prefix}X_train.csv")
    xtest_path  = out_dir / (xtest_file  if xtest_file  else f"{prefix}X_test.csv")
    ytrain_path = out_dir / (ytrain_file if ytrain_file else f"{prefix}y_train.csv")
    ytest_path  = out_dir / (ytest_file  if ytest_file  else f"{prefix}y_test.csv")

    # å†™å‡º
    if save_csv:
        X_train.to_csv(xtrain_path, index=False)
        X_test.to_csv(xtest_path, index=False)
        # æ˜¾å¼å†™å‡ºç›®æ ‡åˆ—åï¼Œä¾¿äºåç»­è¯†åˆ«
        y_train.to_csv(ytrain_path, index=False, header=[target_col])
        y_test.to_csv(ytest_path, index=False, header=[target_col])
        if save_raw:
            xtrain_raw_path = out_dir / (xtrain_raw_file if xtrain_raw_file else f"{prefix}X_train_raw.csv")
            xtest_raw_path  = out_dir / (xtest_raw_file  if xtest_raw_file  else f"{prefix}X_test_raw.csv")
            X_train_raw.to_csv(xtrain_raw_path, index=False)
            X_test_raw.to_csv(xtest_raw_path, index=False)

    if save_npz:
        # è¯´æ˜ï¼šnpz æ˜¯ Numpy çš„å‹ç¼©æ‰“åŒ…æ ¼å¼ï¼Œé€‚åˆåœ¨ Python/NumPy/Sklearn é‡Œå¿«é€ŸåŠ è½½ï¼›
        # å¯¹ä½ æ¥è¯´ä¸æ˜¯â€œå¿…é¡»â€ï¼Œåªæ˜¯ä¾¿æ·é€‰é¡¹ã€‚
        np.savez(
            out_dir / f"{prefix}data.npz",
            X_train=X_train.values,
            X_test=X_test.values,
            y_train=y_train.values,
            y_test=y_test.values,
            feature_names=np.array(feature_cols, dtype=object),
            target_name=np.array([target_col], dtype=object),
            scaled=np.array([do_scale], dtype=bool),
            # â˜… å¯é€‰ï¼šè¿½åŠ åŸå§‹
            X_train_raw=X_train_raw.values,
            X_test_raw=X_test_raw.values,
        )

    # æ§åˆ¶å°æŠ¥å‘Š
    print("===== é¢„å¤„ç†å®Œæˆï¼ˆæ‰‹åŠ¨å¯æ§ç‰ˆï¼‰=====")
    print(f"æ ·æœ¬æ€»æ•°(æœ‰æ•ˆ): {len(X)} | è®­ç»ƒ: {len(X_train)} | æµ‹è¯•: {len(X_test)}")
    print(f"ç›®æ ‡åˆ—: {target_col}")
    print(f"ç‰¹å¾åˆ—ï¼ˆ{len(feature_cols)} ä¸ªï¼‰: {feature_cols}")
    print(f"è®­ç»ƒé›†ç›®æ ‡æœ€å°/æœ€å¤§: {float(y_train.min()):.3f} / {float(y_train.max()):.3f}")
    print(f"æµ‹è¯•é›†ç›®æ ‡æœ€å°/æœ€å¤§: {float(y_test.min()):.3f} / {float(y_test.max()):.3f}")
    print(f"å·²ä¿å­˜è‡³: {out_dir.resolve()}")
    if save_npz:
        print(f"(å·²ç”Ÿæˆ {prefix}data.npz)")

def build_argparser():
    ap = argparse.ArgumentParser()
    ap.add_argument("--input", required=True, help="è¾“å…¥æ•°æ®è·¯å¾„ï¼ˆCSVæˆ–XLSXï¼‰")
    ap.add_argument("--sheet", default=None, help="Excel çš„ sheet ç´¢å¼•æˆ–åç§°ï¼ˆå¯é€‰ï¼‰")
    ap.add_argument("--target", default="UTS", help="ç›®æ ‡åˆ—åï¼ˆé»˜è®¤ UTSï¼‰")
    ap.add_argument("--features", required=True, help="é€—å·åˆ†éš”çš„ç‰¹å¾åˆ—ååˆ—è¡¨ï¼Œå¦‚ï¼šSi,Fe,Cu,Mn,Mg")
    ap.add_argument("--test-size", type=float, default=0.3, help="æµ‹è¯•é›†æ¯”ä¾‹ï¼ˆé»˜è®¤ 0.3ï¼‰")
    ap.add_argument("--random-state", type=int, default=SEED, help="éšæœºç§å­ï¼ˆé»˜è®¤ 42ï¼‰")
    ap.add_argument("--save-raw", action="store_true", help="åŒæ—¶ä¿å­˜æœªæ ‡å‡†åŒ–çš„ X_train_raw/X_test_raw")
    ap.add_argument("--xtrain-raw-file", default=None, help="åŸå§‹ X_train æ–‡ä»¶åï¼ˆå«æ‰©å±•åï¼‰")
    ap.add_argument("--xtest-raw-file", default=None, help="åŸå§‹ X_test  æ–‡ä»¶åï¼ˆå«æ‰©å±•åï¼‰")

    # ç¼©æ”¾ä¸å¡«è¡¥
    grp = ap.add_mutually_exclusive_group()
    grp.add_argument("--scale", dest="scale", action="store_true", help="å¯ç”¨æ ‡å‡†åŒ–ï¼ˆé»˜è®¤å¯ç”¨ï¼‰")
    grp.add_argument("--no-scale", dest="scale", action="store_false", help="ç¦ç”¨æ ‡å‡†åŒ–")
    ap.set_defaults(scale=True)

    ap.add_argument("--impute", choices=["none","median","mean","zero"], default="none",
                    help="ç¼ºå¤±å€¼å¡«è¡¥ç­–ç•¥ï¼ˆé»˜è®¤ none ä¸å¡«è¡¥ï¼Œé‡åˆ°ç¼ºå¤±æŠ¥é”™ï¼‰")

    # è¾“å‡ºæ§åˆ¶
    ap.add_argument("--outdir", default=None, help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä¸è¾“å…¥åŒç›®å½•ï¼‰")
    ap.add_argument("--prefix", default="", help="è¾“å‡ºæ–‡ä»¶åå‰ç¼€ï¼ˆå¦‚ exp1_ï¼‰")
    ap.add_argument("--no-csv", dest="save_csv", action="store_false", help="ä¸ä¿å­˜ CSVï¼ˆé»˜è®¤ä¿å­˜ï¼‰")
    ap.add_argument("--save-npz", action="store_true", help="é¢å¤–ä¿å­˜ä¸€ä¸ª npzï¼ˆå¯é€‰ï¼‰")

    # æ˜¾å¼æ–‡ä»¶åï¼ˆå¯è¦†ç›– prefix è§„åˆ™ï¼‰
    ap.add_argument("--xtrain-file", default=None, help="X_train æ–‡ä»¶åï¼ˆå«æ‰©å±•åï¼‰")
    ap.add_argument("--xtest-file",  default=None, help="X_test æ–‡ä»¶åï¼ˆå«æ‰©å±•åï¼‰")
    ap.add_argument("--ytrain-file", default=None, help="y_train æ–‡ä»¶åï¼ˆå«æ‰©å±•åï¼‰")
    ap.add_argument("--ytest-file",  default=None, help="y_test æ–‡ä»¶åï¼ˆå«æ‰©å±•åï¼‰")
    return ap

def main():
    ap = build_argparser()
    args = ap.parse_args()

    feature_cols = parse_feature_list(args.features)

    preprocess(
        input_path=args.input,
        target_col=args.target,
        feature_cols=feature_cols,
        test_size=args.test_size,
        random_state=args.random_state,
        sheet=args.sheet,
        do_scale=args.scale,
        impute=args.impute,
        outdir=args.outdir,
        prefix=args.prefix,
        save_csv=args.save_csv,
        save_npz=args.save_npz,
        xtrain_file=args.xtrain_file,
        xtest_file=args.xtest_file,
        ytrain_file=args.ytrain_file,
        ytest_file=args.ytest_file,
        save_raw=args.save_raw,
        xtrain_raw_file=args.xtrain_raw_file,
        xtest_raw_file=args.xtest_raw_file,
    )


if __name__ == "__main__":
    # ğŸ‘‡ è¿™é‡Œä½ å¯ä»¥ç›´æ¥å†™å…¥å‚æ•°ï¼ˆå†™æ­»å‚æ•°æ¨¡å¼ï¼‰
    import sys
    sys.argv = [
        "Preprocess.py",
        "--input", r"D:\MLDesignAl\TheFinal\Data\ElementTreatment-UTS\ElementTreatment-UTS-Processed.csv",
        "--target", "UTS",
        "--features", "Si,Fe,Cu,Mn,Mg,Cr,Zn,V,Ti,Zr,Li,Ni,Be,Sc,Ag,Bi,Pb,Al,SS Temp,Ageing Temp,Ageing Time",
        "--test-size", "0.3",
        "--scale",
        "--save-raw",
        "--outdir", r"D:\MLDesignAl\TheFinal\Data\ElementTreatment-UTS\output-Processed",
        "--xtrain-raw-file", "ElementTreatment-UTS-Processed-X_train_raw.csv",
        "--xtest-raw-file",  "ElementTreatment-UTS-Processed-X_test_raw.csv",
        "--prefix", "ElementTreatment-UTS-Processed-",
        "--save-npz"
    ]
    main()

'''
| å‚æ•°                     | åŠŸèƒ½                  | ç¤ºä¾‹                                                 |
| ---------------------- | ------------------- | -------------------------------------------------- |
| `--input`              | æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆCSV æˆ– Excelï¼‰ | `"C:/data/Origin-1293.xlsx"`                       |
| `--target`             | ç›®æ ‡åˆ—åï¼ˆè¾“å‡ºï¼‰            | `"UTS"` æˆ– `"EL"`                                   |
| `--features`           | é€—å·åˆ†éš”çš„è¾“å…¥ç‰¹å¾åˆ—å         | `"Si,Fe,Cu,Mn,Mg,SS Temp,Ageing Temp,Ageing Time"` |
| `--test-size`          | æµ‹è¯•é›†æ¯”ä¾‹               | `0.3`                                              |
| `--scale / --no-scale` | æ˜¯å¦æ ‡å‡†åŒ–ç‰¹å¾             | é»˜è®¤æ ‡å‡†åŒ–ï¼›ä¸æƒ³å°±åŠ  `--no-scale`                            |
| `--impute`             | ç¼ºå¤±å€¼å¡«è¡¥ç­–ç•¥             | `none`ï¼ˆé»˜è®¤ï¼‰ã€`median`ã€`mean`ã€`zero`                  |
| `--outdir`             | è¾“å‡ºæ–‡ä»¶ç›®å½•              | `"C:/Users/Ricardo/Desktop/output"`                |
| `--prefix`             | è¾“å‡ºæ–‡ä»¶åå‰ç¼€             | `"exp1_"`ï¼ˆç»“æœæ–‡ä»¶åä¼šå˜æˆ `exp1_X_train.csv`ï¼‰             |
| `--save-npz`           | æ˜¯å¦ç”Ÿæˆ `.npz` æ–‡ä»¶      | å¯é€‰ï¼ŒåŠ ä¸Šå°±ç”Ÿæˆ                                           |
'''